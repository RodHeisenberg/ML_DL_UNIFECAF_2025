{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e575baa",
   "metadata": {},
   "source": [
    "\n",
    "# üì± Estudo de Caso ‚Äì Detec√ß√£o de SPAM em SMS (Classifica√ß√£o de Texto)\n",
    "**Professor Rodrigo ‚Äì UniFECAF** ‚Ä¢ **Dura√ß√£o:** ~2h ‚Ä¢ **Trabalho:** dupla/trio\n",
    "\n",
    "## üéØ Objetivo\n",
    "Construir um pipeline de **Machine Learning para NLP cl√°ssico** que classifica mensagens SMS como **SPAM** ou **HAM (leg√≠tima)**.\n",
    "\n",
    "- Revisar o **pipeline** de ML (Aulas 01‚Äì02).\n",
    "- Praticar **pr√©-processamento** de texto e **vetoriza√ß√£o** (TF-IDF).\n",
    "- Treinar e avaliar modelos (Naive Bayes, Regress√£o Log√≠stica).\n",
    "- M√©tricas: **Accuracy, Precision, Recall, F1, ROC-AUC** e **RMSE educacional** (probabilidade vs r√≥tulo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59de0f",
   "metadata": {},
   "source": [
    "\n",
    "## üìÇ Dataset (download e upload manual)\n",
    "Usaremos o **SMS Spam Collection** (UCI Repository).\n",
    "\n",
    "üîó Baixe pelo site oficial da UCI:  \n",
    "https://archive.ics.uci.edu/dataset/228/sms+spam+collection\n",
    "\n",
    "> O arquivo costuma se chamar **`SMSSpamCollection`** (texto separado por **TAB**, duas colunas: `label` e `text`).  \n",
    "> Depois de baixar, **fa√ßa o upload** do arquivo na c√©lula abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6af18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üì• Upload do arquivo da UCI (ex.: SMSSpamCollection)\n",
    "from google.colab import files\n",
    "import io, pandas as pd\n",
    "\n",
    "print(\"Selecione o arquivo 'SMSSpamCollection' baixado da UCI\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "filename = next(iter(uploaded))\n",
    "\n",
    "# Tenta ler com header inexistente (duas colunas: label, text)\n",
    "try:\n",
    "    df = pd.read_csv(io.BytesIO(uploaded[filename]), sep='\\t', header=None, names=['label','text'], encoding='utf-8')\n",
    "except Exception as e:\n",
    "    print(\"Falha no parse padr√£o (tab). Tentando outras varia√ß√µes...\", e)\n",
    "    df = pd.read_csv(io.BytesIO(uploaded[filename]), sep='\\t', encoding_errors='ignore', header=None, names=['label','text'])\n",
    "\n",
    "print(\"Amostra:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a18c2",
   "metadata": {},
   "source": [
    "\n",
    "## 1Ô∏è‚É£ Revis√£o r√°pida ‚Äì Pipeline de ML\n",
    "1. Coleta de dados ‚Üí 2. EDA ‚Üí 3. Pr√©-processamento ‚Üí 4. Treinamento ‚Üí 5. Avalia√ß√£o ‚Üí 6. Recomenda√ß√£o\n",
    "\n",
    "**Pergunta (responda em texto):** Em qual etapa voc√™ imagina que gastaremos mais tempo hoje e por qu√™?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e995e42",
   "metadata": {},
   "source": [
    "*Escreva sua resposta aqui*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45b029",
   "metadata": {},
   "source": [
    "\n",
    "## 2Ô∏è‚É£ EDA ‚Äì Explora√ß√£o de Dados\n",
    "Vamos entender a base: quantidade, balanceamento, tamanho dos textos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Informa√ß√µes gerais\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70fddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribui√ß√£o de classes\n",
    "prop = df['label'].value_counts(normalize=True)\n",
    "prop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f388d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tamanho dos textos (n√∫mero de caracteres) - vis√£o r√°pida\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['len'] = df['text'].astype(str).str.len()\n",
    "print(df['len'].describe())\n",
    "plt.figure()\n",
    "df['len'].hist(bins=30)\n",
    "plt.title(\"Distribui√ß√£o do tamanho das mensagens (caracteres)\")\n",
    "plt.xlabel(\"n¬∫ de caracteres\"); plt.ylabel(\"freq.\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ecf140",
   "metadata": {},
   "source": [
    "\n",
    "**Perguntas r√°pidas:**\n",
    "1. A base √© balanceada? O que isso significa para **accuracy**?  \n",
    "2. Mensagens de spam tendem a ser maiores ou menores?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5308d",
   "metadata": {},
   "source": [
    "*Responda aqui*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639dc3d",
   "metadata": {},
   "source": [
    "\n",
    "## 3Ô∏è‚É£ Pr√©-processamento de Texto\n",
    "- Limpeza simples (lowercase).  \n",
    "- **TF-IDF** para transformar texto em vetores num√©ricos.  \n",
    "- **Split** treino/teste com estratifica√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7379c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Label -> bin√°ria (spam=1, ham=0)\n",
    "df['label_bin'] = (df['label'].str.lower().str.strip() == 'spam').astype(int)\n",
    "\n",
    "X_text = df['text'].astype(str)\n",
    "y = df['label_bin']\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Vetoriza√ß√£o TF-IDF (limpeza b√°sica embutida: lowercase=True)\n",
    "tfidf = TfidfVectorizer(lowercase=True, stop_words=None)  # pode testar stop_words='english'\n",
    "X_train = tfidf.fit_transform(X_train_text)\n",
    "X_test  = tfidf.transform(X_test_text)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.mean(), y_test.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a3f3b",
   "metadata": {},
   "source": [
    "\n",
    "## 4Ô∏è‚É£ Modelos e M√©tricas\n",
    "Vamos comparar **Naive Bayes (MultinomialNB)** e **Regress√£o Log√≠stica**.\n",
    "\n",
    "**M√©tricas:**  \n",
    "- **Accuracy**: % de acertos.  \n",
    "- **Precision**: dos que o modelo chamou de *spam*, quantos eram *spam*.  \n",
    "- **Recall**: dos *spam* reais, quantos o modelo pegou.  \n",
    "- **F1**: equil√≠brio entre precision e recall.  \n",
    "- **ROC-AUC**: qu√£o bem o modelo separa classes variando o limiar.  \n",
    "- **RMSE (educacional)**: erro m√©dio das **probabilidades** previstas vs r√≥tulos (0/1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59997843",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, classification_report,\n",
    "    roc_auc_score, RocCurveDisplay\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LogReg\": LogisticRegression(max_iter=200, n_jobs=-1, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ConfusionMatrixDisplay(cm).plot()\n",
    "    plt.title(f\"{name} - Matriz de Confus√£o (Teste)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Probabilidades para AUC e RMSE (se dispon√≠vel)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        # fallback para modelos sem predict_proba (n√£o √© o caso aqui)\n",
    "        y_score = None\n",
    "\n",
    "    if y_score is not None:\n",
    "        auc = roc_auc_score(y_test, y_score)\n",
    "        print(f\"ROC-AUC: {auc:.4f}\")\n",
    "        RocCurveDisplay.from_predictions(y_test, y_score)\n",
    "        plt.title(f\"{name} - Curva ROC (Teste)\")\n",
    "        plt.show()\n",
    "\n",
    "        # RMSE educacional (probabilidade vs r√≥tulo)\n",
    "        rmse = np.sqrt(np.mean((y_score - y_test.values)**2))\n",
    "        print(f\"RMSE (probabilidade vs r√≥tulo): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8a380",
   "metadata": {},
   "source": [
    "\n",
    "### üí¨ Perguntas finais (responda em texto)\n",
    "1. Qual modelo apresentou melhor equil√≠brio entre **precision** e **recall**?  \n",
    "2. Para um filtro de spam corporativo, voc√™ priorizaria **precision** ou **recall**? Explique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6b1f20",
   "metadata": {},
   "source": [
    "*Escreva aqui suas respostas*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95c163",
   "metadata": {},
   "source": [
    "\n",
    "## üìù Reflex√£o do Grupo (obrigat√≥ria)\n",
    "**Dificuldades encontradas:**  \n",
    "- ...\n",
    "\n",
    "**O que aprendemos:**  \n",
    "- ...\n",
    "\n",
    "**Como aplicar na TI (seguran√ßa, e-mail corporativo, antiphishing):**  \n",
    "- ...\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deteccao_SPAM_SMS_ALUNO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
